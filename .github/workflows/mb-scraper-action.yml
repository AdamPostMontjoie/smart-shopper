name: Weekly Scraper

on:
  schedule:
    # Runs at 8:00 AM UTC every Sunday
    - cron: '0 13 * * 0'
  workflow_dispatch: # Manual run button
  push:
    branches:
      - master

jobs:
  scrape-with-docker:
    runs-on: ubuntu-latest
    
    # We don't need 'defaults' anymore because Docker handles the path
    steps:
      - uses: actions/checkout@v3

      # Step 1: Build the "Slim" Image using your Dockerfile
      # This reads web-scraper/Dockerfile and installs the lightweight libraries
      - name: Build Scraper Image
        run: |
          cd web-scraper
          docker build -t scraper-image .

      # Step 2: Run the container
      # We pass the secrets into the container using -e
      - name: Run Scraper Container
        run: |
          docker run --rm \
          -e SUPABASE_URL="${{ secrets.SUPABASE_URL }}" \
          -e SUPABASE_KEY="${{ secrets.SUPABASE_KEY }}" \
          scraper-image